{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get textblob\n",
    "\n",
    "[textblob](https://pypi.python.org/pypi/textblob) is an external library that is neither included as part of the Python Standard Library nor with the tools that Anaconda bundles together.  You will need to go to the commandline/command prompt and run `pip install textblob`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functioning textblob example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "# This next line takes the content of 'text' and passes it as input to the the TextBlob function.  \n",
    "blob = TextBlob(text)\n",
    "\n",
    "# uncomment the following line to see how textblob does tagging\n",
    "# print(blob.tags)           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "# uncommend the following line to see how textblob does noun phrases\n",
    "# print(blob.noun_phrases)   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity) # Should return 0.060\n",
    "    print(sentence.sentiment.index) # Should return # -0.341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully functioning sentiment analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numpy.random import rand\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via', 'RT', 'â€¦']\n",
    "\n",
    "#Instantiate a text pre-processor\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "fname = 'trumpStream.json'\n",
    "each_tweet=[]\n",
    "\n",
    "#drawing on http://www.saltycrane.com/blog/2008/06/how-to-get-current-date-and-time-in/\n",
    "#drawing on http://stackoverflow.com/questions/796008/cant-subtract-offset-naive-and-offset-aware-datetimes\n",
    "datemin = None\n",
    "datemax = None\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        # print(tweet['text'])\n",
    "        each_tweet.append([tweet['created_at'],tweet['text']])\n",
    "        # print(each_tweet)\n",
    "    points=[]\n",
    "    for tweet_deets in each_tweet:\n",
    "        #print(tweet_text)\n",
    "        blob = TextBlob(tweet_deets[1])\n",
    "        \n",
    "        #print(blob)\n",
    "        #print(tweet_deets[0][:50], \" : \", blob.sentiment.polarity)\n",
    "        \n",
    "        #Time directives taken from https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior\n",
    "        #Date conversion from http://stackoverflow.com/questions/2265357/parse-date-string-and-change-format\n",
    "        tweet_date = datetime.strptime(tweet_deets[0], '%a %b %d %H:%M:%S %z %Y')\n",
    "        \n",
    "        #print(type(tweet_date),tweet_date)\n",
    "        \n",
    "        if datemax is None or tweet_date > datemax: datemax = tweet_date\n",
    "        if datemin is None or tweet_date < datemin: datemin = tweet_date\n",
    "        points.append([tweet_date,blob.sentiment.polarity])\n",
    "        #print(tweet_date)\n",
    "    \n",
    "    plt.scatter([item[0] for item in points] , [item[1] for item in points], c='red', alpha=0.3, edgecolors='none')\n",
    "\n",
    "# Drawing on http://matplotlib.org/examples/lines_bars_and_markers/scatter_with_legend.html \n",
    "# Also drawing on http://matplotlib.org/examples/pylab_examples/date_demo_rrule.html\n",
    "\n",
    "plt.xlim(datemin - timedelta(days=0.001),datemax + timedelta(days=0.001))\n",
    "plt.xticks(rotation='45')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
