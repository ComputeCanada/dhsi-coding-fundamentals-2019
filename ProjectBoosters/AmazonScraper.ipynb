{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool that Tatiana was working with is a GitHub repository.  Jupyter notebooks allow you to make command line calls from inside them.  Not sure how this will work on Windows machines but I'll write it up here anyway for overall simplicity.  If you find some command line code failing then you can just copy and paste it into the Anaconda Prompt.\n",
    "\n",
    "In the notebooks preceeding a line with a `!` tells the notebook to run the line as a shell command.  The `!` is not part of Python, it is part of the notebook environment.\n",
    "\n",
    "First piece of preparation is to read the README file.  Let's make this easy to do locally by by downloading the repository into the directory that you have put this file in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amazon-reviews-scrapy'...\n",
      "remote: Enumerating objects: 99, done.\u001b[K\n",
      "remote: Total 99 (delta 0), reused 0 (delta 0), pack-reused 99\u001b[K\n",
      "Unpacking objects: 100% (99/99), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/AjinkyaIndulkar/amazon-reviews-scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you read the file you'll note that you need to install some software.  This should be straightforward with `pip` and can all be done in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/45/414e87ac8209d537c91575538c5307c20217a6943f555e0ee39f6db4bb0f/Scrapy-1.6.0-py2.py3-none-any.whl (231kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plac in /Users/simpson/anaconda3/lib/python3.6/site-packages (0.9.6)\n",
      "Collecting pyfiglet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/07/fcfdd7a2872f5b348953de35acce1544dab0c1e8368dca54279b1cde5c15/pyfiglet-0.8.post1-py2.py3-none-any.whl (865kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/simpson/anaconda3/lib/python3.6/site-packages (4.28.1)\n",
      "Requirement already satisfied: pandas in /Users/simpson/anaconda3/lib/python3.6/site-packages (0.22.0)\n",
      "Collecting googletrans\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/81/43/9dcf92a77f5f0afe4f4df2407d7289eea01368a08b64bda00dd318ca62a6/w3lib-1.20.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml in /Users/simpson/anaconda3/lib/python3.6/site-packages (from scrapy) (4.1.1)\n",
      "Collecting parsel>=1.5 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/69/d1d5dba5e4fecd41ffd71345863ed36a45975812c06ba77798fc15db6a64/parsel-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from scrapy) (1.11.0)\n",
      "Requirement already satisfied: cssselect>=0.9 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from scrapy) (1.0.3)\n",
      "Collecting Twisted>=13.1.0 (from scrapy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/59/035de19362320e632301ed7bbde23e4c8cd6fc5e2f1cf8d354cdba857854/Twisted-19.2.1.tar.bz2 (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 8.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting service-identity (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
      "Collecting queuelib (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyOpenSSL in /Users/simpson/anaconda3/lib/python3.6/site-packages (from scrapy) (17.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from pandas) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/simpson/anaconda3/lib/python3.6/site-packages (from pandas) (2017.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: requests in /Users/simpson/anaconda3/lib/python3.6/site-packages (from googletrans) (2.22.0)\n",
      "Collecting zope.interface>=4.4.2 (from Twisted>=13.1.0->scrapy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/11/0d2c7017ee0014801251470b4ace8590ff6f8acdf431b04e08cdb2661246/zope.interface-4.6.0-cp36-cp36m-macosx_10_6_intel.whl (140kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 11.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting constantly>=15.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
      "Collecting incremental>=16.10.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
      "Collecting Automat>=0.3.0 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/86/14c16bb98a5a3542ed8fed5d74fb064a902de3bdd98d6584b34553353c45/Automat-0.7.0-py2.py3-none-any.whl\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/91/e916ca10a2de1cb7101a9b24da546fb90ee14629e23160086cf3361c4fb8/hyperlink-19.0.0-py2.py3-none-any.whl\n",
      "Collecting PyHamcrest>=1.9.0 (from Twisted>=13.1.0->scrapy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d5/d37fd731b7d0e91afcc84577edeccf4638b4f9b82f5ffe2f8b62e2ddc609/PyHamcrest-1.9.0-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from Twisted>=13.1.0->scrapy) (17.4.0)\n",
      "Requirement already satisfied: pyasn1 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from service-identity->scrapy) (0.4.3)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/simpson/anaconda3/lib/python3.6/site-packages (from service-identity->scrapy) (0.2.2)\n",
      "Requirement already satisfied: cryptography in /Users/simpson/anaconda3/lib/python3.6/site-packages (from service-identity->scrapy) (2.6.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from requests->googletrans) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from requests->googletrans) (2019.3.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from requests->googletrans) (1.22)\n",
      "Requirement already satisfied: setuptools in /Users/simpson/anaconda3/lib/python3.6/site-packages (from zope.interface>=4.4.2->Twisted>=13.1.0->scrapy) (38.4.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from cryptography->service-identity->scrapy) (0.24.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /Users/simpson/anaconda3/lib/python3.6/site-packages (from cryptography->service-identity->scrapy) (1.11.4)\n",
      "Requirement already satisfied: pycparser in /Users/simpson/anaconda3/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->service-identity->scrapy) (2.18)\n",
      "Building wheels for collected packages: googletrans, PyDispatcher, Twisted\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/simpson/Library/Caches/pip/wheels/50/d6/e7/a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\n",
      "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/simpson/Library/Caches/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
      "  Building wheel for Twisted (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/simpson/Library/Caches/pip/wheels/19/4c/a1/0bef832134076abab3461815e92cf41f2518dffe1a5337203b\n",
      "Successfully built googletrans PyDispatcher Twisted\n",
      "Installing collected packages: PyDispatcher, w3lib, parsel, zope.interface, constantly, incremental, Automat, hyperlink, PyHamcrest, Twisted, service-identity, queuelib, scrapy, pyfiglet, googletrans\n",
      "Successfully installed Automat-0.7.0 PyDispatcher-2.0.5 PyHamcrest-1.9.0 Twisted-19.2.1 constantly-15.1.0 googletrans-2.4.0 hyperlink-19.0.0 incremental-17.5.0 parsel-1.5.1 pyfiglet-0.8.post1 queuelib-1.5.0 scrapy-1.6.0 service-identity-18.1.0 w3lib-1.20.0 zope.interface-4.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scrapy plac pandas googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the software installed we can attempt to run a search and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _                                     ____            _                   \n",
      "   / \\   _ __ ___   __ _ _______  _ __   |  _ \\ _____   _(_) _____      _____ \n",
      "  / _ \\ | '_ ` _ \\ / _` |_  / _ \\| '_ \\  | |_) / _ \\ \\ / / |/ _ \\ \\ /\\ / / __|\n",
      " / ___ \\| | | | | | (_| |/ / (_) | | | | |  _ <  __/\\ V /| |  __/\\ V  V /\\__ \\\n",
      "/_/   \\_\\_| |_| |_|\\__,_/___\\___/|_| |_| |_| \\_\\___| \\_/ |_|\\___| \\_/\\_/ |___/\n",
      "                                                                              \n",
      "__        __   _       ____                                       \n",
      "\\ \\      / /__| |__   / ___|  ___ _ __ __ _ _ __  _ __   ___ _ __ \n",
      " \\ \\ /\\ / / _ \\ '_ \\  \\___ \\ / __| '__/ _` | '_ \\| '_ \\ / _ \\ '__|\n",
      "  \\ V  V /  __/ |_) |  ___) | (__| | | (_| | |_) | |_) |  __/ |   \n",
      "   \\_/\\_/ \\___|_.__/  |____/ \\___|_|  \\__,_| .__/| .__/ \\___|_|   \n",
      "                                           |_|   |_|              \n",
      "\n",
      "\n",
      "======\n",
      "python run_asin_fetcher.py -c all -k outer suburbia\n",
      "======\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"amazon-reviews-scrapy/run_amazon_reviews.py\", line 86, in <module>\n",
      "    plac.call(main)\n",
      "  File \"/Users/simpson/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 328, in call\n",
      "    cmd, result = parser.consume(arglist)\n",
      "  File \"/Users/simpson/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 207, in consume\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
      "  File \"amazon-reviews-scrapy/run_amazon_reviews.py\", line 75, in main\n",
      "    p_status = run_for_asin(c)\n",
      "  File \"amazon-reviews-scrapy/run_amazon_reviews.py\", line 26, in run_for_asin\n",
      "    p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=False, cwd=cwd)\n",
      "  File \"/Users/simpson/anaconda3/lib/python3.6/subprocess.py\", line 729, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/Users/simpson/anaconda3/lib/python3.6/subprocess.py\", line 1364, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/simpson/Documents/workspace/DHSI-CodingFundamentals/2019/Boosters\\\\amazon_asin_fetcher': '/Users/simpson/Documents/workspace/DHSI-CodingFundamentals/2019/Boosters\\\\amazon_asin_fetcher'\n"
     ]
    }
   ],
   "source": [
    "! python amazon-reviews-scrapy/run_amazon_reviews.py -c all -k \"outer suburbia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It fails for me, as you can see above.  Two reasons for this and both amount to Python saying, \"I can't find the directory with this other thing you want (amazon_asin_fetcher)\":\n",
    "\n",
    "1. \"No such file or directory: /Users/simpson/Documents/workspace/DHSI-CodingFundamentals/2019/Boosters\\\\amazon_asin_fetcher...\"  See the swapping between `/` and `\\\\` part way through?  This suggests to me that this was created for/on Windows and I've got a Mac so the _format_ of the file names is going to be wrong.\n",
    "2. Even if the formatting was right that directory–`.../Boosters/amazon_asin_fetcher`–doesn't exist.  `.../Boosters/amazon-reviews-scrapy/amazon_asin_fetcher` exists.  We're getting the wrong directory because we're calling python from a different directory and because of how relative addressing works it's going to look in the directory that we called Python from and not where we told it the file was.\n",
    "\n",
    "To solve #1 I'm going to edit the code.  If you have a Windows machkine you can likely ignore this.  To solve #2 you can either resave this workbook inside the `amazon-reviews-scrapy` directory _or_ just run everything directly in the shell from here on out.\n",
    "\n",
    "File modifications needed were found on the documentation page for the `process` module (https://docs.python.org/3/library/subprocess.html#popen-constructor):\n",
    "\n",
    "1. Add `import shlex` to the top of the file.\n",
    "2. Add `command = shlex.split(command)` just before the line `p = subprocess.Popen(command,...` in _both_ the `run_for_asin()` and the `run_for_reviews()` functions.\n",
    "\n",
    "Running the file again moves us forward but still ends in an error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        $ python run_amazon_reviews.py -c all -k \"outer suburbia\"\n",
    "            _                                     ____            _                   \n",
    "           / \\   _ __ ___   __ _ _______  _ __   |  _ \\ _____   _(_) _____      _____ \n",
    "          / _ \\ | '_ ` _ \\ / _` |_  / _ \\| '_ \\  | |_) / _ \\ \\ / / |/ _ \\ \\ /\\ / / __|\n",
    "         / ___ \\| | | | | | (_| |/ / (_) | | | | |  _ <  __/\\ V /| |  __/\\ V  V /\\__ \\\n",
    "        /_/   \\_\\_| |_| |_|\\__,_/___\\___/|_| |_| |_| \\_\\___| \\_/ |_|\\___| \\_/\\_/ |___/\n",
    "\n",
    "        __        __   _       ____                                       \n",
    "        \\ \\      / /__| |__   / ___|  ___ _ __ __ _ _ __  _ __   ___ _ __ \n",
    "         \\ \\ /\\ / / _ \\ '_ \\  \\___ \\ / __| '__/ _` | '_ \\| '_ \\ / _ \\ '__|\n",
    "          \\ V  V /  __/ |_) |  ___) | (__| | | (_| | |_) | |_) |  __/ |   \n",
    "           \\_/\\_/ \\___|_.__/  |____/ \\___|_|  \\__,_| .__/| .__/ \\___|_|   \n",
    "                                                   |_|   |_|              \n",
    "\n",
    "\n",
    "        ======\n",
    "        python run_asin_fetcher.py -c all -k outer suburbia\n",
    "        ======\n",
    "\n",
    "        ['python', 'run_asin_fetcher.py', '-c', 'all', '-k', 'outer', 'suburbia']\n",
    "        usage: run_asin_fetcher.py [-h] [-c None] [-k None]\n",
    "        run_asin_fetcher.py: error: unrecognized arguments: suburbia\n",
    "        Current Task Complete...\n",
    "\n",
    "        ======\n",
    "        python fix_json.py\n",
    "        ======\n",
    "\n",
    "        ['python', 'fix_json.py']\n",
    "        Traceback (most recent call last):\n",
    "          File \"fix_json.py\", line 60, in <module>\n",
    "            main()\n",
    "          File \"fix_json.py\", line 51, in main\n",
    "            json_files = [f for f in os.listdir('./Output/Original') if path.isfile(path.join('./Output/Original', f))]\n",
    "        FileNotFoundError: [Errno 2] No such file or directory: './Output/Original'\n",
    "        Current Task Complete...\n",
    "\n",
    "        ======\n",
    "        python json2excel.py\n",
    "        ======\n",
    "\n",
    "        ['python', 'json2excel.py']\n",
    "        Traceback (most recent call last):\n",
    "          File \"json2excel.py\", line 56, in <module>\n",
    "            main()\n",
    "          File \"json2excel.py\", line 35, in main\n",
    "            json_files = [f for f in os.listdir('./Output/New/') if isfile(join('./Output/New/', f))]\n",
    "        FileNotFoundError: [Errno 2] No such file or directory: './Output/New/'\n",
    "        Current Task Complete...\n",
    "\n",
    "        Copying ASIN_Data...\n",
    "        Traceback (most recent call last):\n",
    "          File \"run_amazon_reviews.py\", line 91, in <module>\n",
    "            plac.call(main)\n",
    "          File \"/Users/simpson/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 328, in call\n",
    "            cmd, result = parser.consume(arglist)\n",
    "          File \"/Users/simpson/anaconda3/lib/python3.6/site-packages/plac_core.py\", line 207, in consume\n",
    "            return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
    "          File \"run_amazon_reviews.py\", line 83, in main\n",
    "            copy_file()\n",
    "          File \"run_amazon_reviews.py\", line 41, in copy_file\n",
    "            shutil.copy(src, dest)\n",
    "          File \"/Users/simpson/anaconda3/lib/python3.6/shutil.py\", line 245, in copy\n",
    "            copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
    "          File \"/Users/simpson/anaconda3/lib/python3.6/shutil.py\", line 120, in copyfile\n",
    "            with open(src, 'rb') as fsrc:\n",
    "        FileNotFoundError: [Errno 2] No such file or directory: '/Users/simpson/Documents/workspace/DHSI-CodingFundamentals/2019/Boosters/amazon-reviews-scrapy/amazon_asin_fetcher/Data/ASIN_Data.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it can't find a file, or at least the directory that file is in (formatting is right for a Mac though!).  If we go looking through the directory structure it is pretty clear that `.../amazon-reviews-scrapy/amazon_asin_fetcher/Data/` isn't there.  Should it be?  Is the `.../Data/` directory elsewhere?  Looks like it is.  I'm not sure if we should add the directory to `.../amazon_asin_fetcher/` or modify the code to point to the `.../Data/` directory that already exists.  I suspect the latter but we'll need to look further or just try and see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
